{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "from splinter.exceptions import ElementDoesNotExist\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs of pages to be scraped\n",
    "nasa_url = 'https://mars.nasa.gov/news/'\n",
    "jpl_url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "mars_weather_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "mars_facts_url = 'https://space-facts.com/mars/'\n",
    "usgs_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "\n",
    "# start browser for splinter\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASA Mars News\n",
    "Scrape the NASA Mars News Site and collect the latest News Title and Paragraph Text. Assign the text to variables that you can reference later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with the requests module\n",
    "response_nasa = requests.get(nasa_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup_nasa = bs(response_nasa.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contains sought info\n",
    "# print(soup_nasa.prettify()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the NASA Website\n",
    "browser.visit(nasa_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<div class=\"content_title\">\n",
      "<a href=\"/news/8426/nasa-garners-7-webby-award-nominations/\">\n",
      "NASA Garners 7 Webby Award Nominations\n",
      "</a>\n",
      "</div>, <div class=\"content_title\">\n",
      "<a href=\"/news/8413/nasas-opportunity-rover-mission-on-mars-comes-to-end/\">\n",
      "NASA's Opportunity Rover Mission on Mars Comes to End\n",
      "</a>\n",
      "</div>, <div class=\"content_title\">\n",
      "<a href=\"/news/8402/nasas-insight-places-first-instrument-on-mars/\">\n",
      "NASA's InSight Places First Instrument on Mars\n",
      "</a>\n",
      "</div>, <div class=\"content_title\">\n",
      "<a href=\"/news/8387/nasa-announces-landing-site-for-mars-2020-rover/\">\n",
      "NASA Announces Landing Site for Mars 2020 Rover\n",
      "</a>\n",
      "</div>, <div class=\"content_title\">\n",
      "<a href=\"/news/8348/opportunity-hunkers-down-during-dust-storm/\">\n",
      "Opportunity Hunkers Down During Dust Storm\n",
      "</a>\n",
      "</div>, <div class=\"content_title\">\n",
      "<a href=\"/news/8347/nasa-finds-ancient-organic-material-mysterious-methane-on-mars/\">\n",
      "NASA Finds Ancient Organic Material, Mysterious Methane on Mars\n",
      "</a>\n",
      "</div>]\n"
     ]
    }
   ],
   "source": [
    "# a = soup_nasa.find(\"div\", class_=\"list_text\")\n",
    "news_title = soup_nasa.find_all(\"div\", class_=\"content_title\")\n",
    "print(news_title)\n",
    "# soup_nasa.find('ul', class_='item_list')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_nasa.find('div', class_='list_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_p = soup_nasa.find_all('div', class_='article_teaser_body')\n",
    "news_p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the url for JPL Featured Space Image\n",
    "browser.visit(jpl_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use splinter to navigate the site and find the image url for the current Featured Mars Image \n",
    "# and assign the url string to a variable called featured_image_url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Weather\n",
    "Visit the Mars Weather twitter account and scrape the latest Mars weather tweet from the page. Save the tweet text for the weather report as a variable called mars_weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars Facts webpage and use Pandas to scrape the table containing facts about the planet \n",
    "# including Diameter, Mass, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas to convert the data to a HTML table string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mars Hemispheres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visit the USGS Astrogeology site to obtain high resolution images for each of Mar's hemispheres.\n",
    "- You will need to click each of the links to the hemispheres in order to find the image url to the full resolution image.\n",
    "- Save both the image url string for the full resolution hemisphere image, and the Hemisphere title containing the hemisphere name. Use a Python dictionary to store the data using the keys img_url and title.\n",
    "- Append the dictionary with the image url string and the hemisphere title to a list. This list will contain one dictionary for each hemisphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - MongoDB and Flask Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
